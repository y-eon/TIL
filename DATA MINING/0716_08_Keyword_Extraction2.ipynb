{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"08 Prac 2. Keyword Extraction의 직접 구현의 사본","provenance":[{"file_id":"1rtEOh-KEyOrPz5bmJ4KUur6m3Hcrgwar","timestamp":1594888686505}],"collapsed_sections":["hpTxmnbx8v6m"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"q1Q9mWDrgMUn","colab_type":"text"},"source":["# 8장. 핵심 키워드 추출 (Keyword Extraction)"]},{"cell_type":"markdown","metadata":{"id":"PSZIeetL8Yym","colab_type":"text"},"source":["# 8-0 데이터 준비"]},{"cell_type":"markdown","metadata":{"id":"hpTxmnbx8v6m","colab_type":"text"},"source":["## Mecab 설치 (필요시)"]},{"cell_type":"code","metadata":{"id":"qsWnZkd78qCA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2dd9dd39-5656-4093-aeef-02c815d6b270"},"source":["!sudo apt-get install g++ openjdk-7-jdk # Install Java 1.7+\n","!sudo apt-get install python-dev; pip install konlpy     # Python 2.x\n","!sudo apt-get install python3-dev; pip3 install konlpy   # Python 3.x\n","!sudo apt-get install curl\n","!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 6%\r"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jxsBfWirA9ao","colab_type":"text"},"source":["# 8-1 TF-IDF 활용 핵심키워드 추출"]},{"cell_type":"markdown","metadata":{"id":"u8UYUNHDNMVp","colab_type":"text"},"source":["## 실습 1. sklearn 활용\n"]},{"cell_type":"code","metadata":{"id":"fdsHZk1UBtRP","colab_type":"code","colab":{}},"source":["import requests \n","from bs4 import BeautifulSoup\n","\n","def get_news_by_url(url):\n","  res = requests.get(url)\n","  bs = BeautifulSoup(res.content, 'html.parser')\n","\n","  title = bs.select('h3#articleTitle')[0].text #제목\n","  content = bs.select('#articleBodyContents')[0].get_text().replace('\\n', \" \") #본문\n","  content = content.replace(\"// flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}\", \"\")\n","  return  content.strip()\n","\n","docs = []\n","docs.append( get_news_by_url('https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=105&oid=018&aid=0004430108') )\n","docs.append( get_news_by_url('https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=001&aid=0011614790') )\n","docs.append( get_news_by_url('https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=102&oid=014&aid=0004424362') )\n","docs.append( get_news_by_url('https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=119&aid=0002402191') )\n","docs.append( get_news_by_url('https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=030&aid=0002882728') )\n","len(docs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Of0dQ_ALpLw6","colab_type":"text"},"source":["### 1) 전처리"]},{"cell_type":"code","metadata":{"id":"tfGX-_IxAbgt","colab_type":"code","colab":{}},"source":["from konlpy.tag import Mecab\n","mecab = Mecab()\n","\n","preprocessed_docs = []\n","for doc in docs :\n","  # 명사와 동사만으로 문서 전처리\n","  preprocessed_docs.append(' '.join([token[0] for token in mecab.pos(doc) if token[1][0] in ['N', 'V']]))\n","preprocessed_docs[0][:100]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JqZ9ONgLpOzv","colab_type":"text"},"source":["### 2) TF-IDF 계산"]},{"cell_type":"code","metadata":{"id":"Okub07GQ-KJe","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","count_vectorizer = CountVectorizer(max_df=0.85, max_features=10000)\n","word_count_vector = count_vectorizer.fit_transform(preprocessed_docs)\n","list(count_vectorizer.vocabulary_.keys())[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9oMnmGfp6PAb","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"em3l3IS5kRP-","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import TfidfTransformer\n","\n","tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n","tfidf_transformer.fit(word_count_vector)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"an6Cngd2Cwjg","colab_type":"text"},"source":["### 3) 핵심키워드 추출"]},{"cell_type":"code","metadata":{"id":"yKrcZ9rh-5Rt","colab_type":"code","colab":{}},"source":["def sort_keywords(keywords):\n","    return sorted(zip(keywords.col, keywords.data), key=lambda x: (x[1], x[0]), reverse=True)\n"," \n","def extract_keywords(feature_names, sorted_keywords, n=5):\n","    return [(feature_names[idx], score) for idx, score in sorted_keywords[:n]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u_8wXmex-1gr","colab_type":"code","colab":{}},"source":["doc = preprocessed_docs[0] # 핵심키워드 추출할 문서 조회\n","\n","feature_names = count_vectorizer.get_feature_names() # TF-IDF 단어 목록\n","tf_idf_vector = tfidf_transformer.transform(count_vectorizer.transform([doc])) # 문서의 tf-idf 추출\n","sorted_keywords = sort_keywords(tf_idf_vector.tocoo()) # TF-IDF를 기준으로 역순 정렬\n"," \n","# 사용자가 지정한 갯수만큼 키워드 추출\n","keywords = extract_keywords(feature_names, sorted_keywords, 5)\n"," \n","print(\"\\n===== 원문 =====\")\n","print(docs[0][:100])\n","print(\"\\n=== 핵심키워드 ===\")\n","for k in keywords:\n","    print(k)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kUVTXBYrZMiU","colab_type":"code","colab":{}},"source":["tf_idf_vector.tocoo().data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lwQjPYuxNy4K","colab_type":"text"},"source":["\n","---\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XTNnFrNhOrA3"},"source":["## 실습 2. gensim 활용\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aE-YzDI6OrA5"},"source":["### 1) 전처리"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"edVMwQBuOrA6","colab":{}},"source":["from konlpy.tag import Mecab\n","mecab = Mecab()\n","\n","preprocessed_docs = []\n","for doc in docs :\n","  # 명사와 동사만으로 문서 전처리\n","  preprocessed_docs.append(' '.join([token[0] for token in mecab.pos(doc) if token[1][0] in ['N', 'V']]))\n","preprocessed_docs[0][:100]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cWGsCRJUOrA8"},"source":["### 2) TF-IDF 계산"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NCUzeqp3OrA9","colab":{}},"source":["from gensim.models import TfidfModel\n","from gensim.corpora import Dictionary\n","\n","document_ls = [doc.split() for doc in preprocessed_docs]\n","dct = Dictionary(document_ls) # 인덱스(key) - 단어(valuue) 인 딕셔너리 생성\n","corpus = [dct.doc2bow(doc) for doc in document_ls] # 각 문서에 포함된 단어를 인덱스로 변환하여 corpus 생성\n","tfidf = TfidfModel(corpus) # TF-IDF 산출"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wBT2h57bOrBF"},"source":["### 3) 핵심키워드 추출"]},{"cell_type":"code","metadata":{"id":"Xk0Tbo21RddA","colab_type":"code","colab":{}},"source":["def sort_keywords(tfidf):\n","    return sorted(tfidf, key=lambda x: (x[1], x[0]), reverse=True)\n","\n","def extract_keywords(feature_names, sorted_keywords, n=5):\n","    return [(feature_names[idx], score) for idx, score in sorted_keywords[:n]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_8T0QSKVRfUt","colab_type":"code","colab":{}},"source":["doc = corpus[0]\n","\n","sorted_keywords = sort_keywords(tfidf[doc]) # TF-IDF를 기준으로 역순 정렬\n","\n","# 사용자가 지정한 갯수만큼 키워드 추출\n","keywords = extract_keywords(dct, sorted_keywords, 5)\n","\n","print(\"\\n=== 핵심키워드 ===\")\n","for k in keywords:\n","    print(k)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8gBGnkhCZSlw","colab_type":"code","colab":{}},"source":["tfidf[doc]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hZpm1wtTqxL-","colab_type":"text"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mfekkYshBAVS","colab_type":"text"},"source":["# 8-2 Textrank\n","https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf"]},{"cell_type":"markdown","metadata":{"id":"bn58myMFF-nN","colab_type":"text"},"source":["<img src=\"https://3.bp.blogspot.com/-yp0Lr3ec5EY/XIs6znCcO_I/AAAAAAAAAPY/xtZxe_OYtH0xeuWsp4Qd4DQrunGMpVQmQCLcBGAs/s640/keyword-extraction-textrank.png\" />"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kxZBz6vLlyga"},"source":["## 실습 1. 행렬 활용 \n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9QmtIyyHlygg"},"source":["### 1) 토큰화 (Tokenization)\n","\n","분석 텍스트 정제"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YBJSuIvKlygw"},"source":["### 2) Unique한 토큰 목록 생성\n","\n","그래프 생성을 위해서 Unique한 토큰 목록 생성"]},{"cell_type":"code","metadata":{"id":"X-WdT3gz3FMc","colab_type":"code","colab":{}},"source":["token = ['딸기', '바나나', '사과', '딸기', '파인애플']\n","nodes = ['바나나', '사과', '파인애플', '딸기']\n","vocab = nodes\n","\n","vocab2idx = {vocab[i] : i for i in range(len(vocab))} #vocab을 인덱스로 변환\n","idx2vocab = {i : vocab[i] for i in range(len(vocab))} #인덱스를 vocab으로 변환\n","vocab2idx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h5_DwRpOlygz","colab":{}},"source":["len(token)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"P9Tvibn1lyg3"},"source":["### 3) 그래프 생성 (weighted edge 계산)\n","\n","*   TextRank는 그래프 기반 모델\n","*   각 단어(토큰)은 그래프의 노드(vertex) \n","*   weighted_edge 행렬은 노드간 가중치 정보를 담고 있음\n","*   weighted_edge[i][j] 는 i번째 단어와 j번째 단어의 가중치를 의미\n","*   weighted_edge[i][j] 가 0인 경우는 노드간 연결이 없음을 의미\n","*   모든 노드는 1로 초기화"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nP8PJUnMlyg3","colab":{}},"source":["import numpy as np\n","import math\n","vocab_len = len(vocab)\n","\n","# 토큰별로 그래프 edge를 Matrix 형태로 생성\n","weighted_edge = np.zeros((vocab_len, vocab_len))\n","\n","# 각 토큰 노드별로 스코어 1로 초기화\n","score = np.ones((vocab_len))\n","\n","\n","\n","# coocurrence를 판단하기 위한 window 사이즈 설정\n","window_size = 2\n","covered_coocurrences = []\n","\n","# weighted_edge 구현\n","for window_start in range(len(token) - window_size + 1):\n","  window = token[window_start : window_start + window_size]\n","  for i in range(window_size):\n","    for j in range(i + 1, window_size ):\n","      if window[i] in vocab2idx.keys() and window[j] in vocab2idx.keys():\n","        index_i = window_start + i\n","        index_j = window_start + j\n","\n","        if [index_i, index_j] not in covered_coocurrences:\n","          weighted_edge[vocab2idx[window[i]]][vocab2idx[window[j]]] = 1\n","          weighted_edge[vocab2idx[window[j]]][vocab2idx[window[i]]] = 1\n","          covered_coocurrences.append([index_i, index_j])\n","\n","\n","for i in range(len(vocab)):\n","  sumi = weighted_edge[i].sum()\n","  weighted_edge[i] = weighted_edge[i]/sumi if sumi > 0 else 0\n","  \n","\n","\n","\n","weighted_edge"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"loXJ9c7jlyg8"},"source":["### 4) 각 노드의 score계산\n","각 노드와 연결된 weighted edge의 값을 합산"]},{"cell_type":"code","metadata":{"id":"VQOFf2NRuJG8","colab_type":"code","colab":{}},"source":["MAX_ITERATIONS = 50\n","d=0.85\n","threshold = 0.0001 #convergence threshold\n","score = np.ones((vocab_len))\n","\n","\n","for iter in range(0,MAX_ITERATIONS):\n","    prev_score = np.copy(score)\n","    \n","    for i in range(len(vocab)):\n","      summation = 0\n","      for j in range(len(vocab)):\n","        if weighted_edge[j][i] != 0:\n","          summation += weighted_edge[j][i] * score[j]\n","\n","        score[i] = (1 -d) + d * (summation)\n","\n","      if np.sum(np.fabs(prev_score - score)) <= threshold:\n","        break\n","score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R9IOS9Oolyg8","colab":{}},"source":["MAX_ITERATIONS = 50\n","d=0.85\n","threshold = 0.0001 #convergence threshold\n","score = np.ones((vocab_len))\n","\n","\n","for iter in range(0,MAX_ITERATIONS):\n","    prev_score = np.copy(score)\n","    \n","    for i in range(len(vocab)):\n","      summation = 0\n","      for j in range(len(vocab)):\n","        if weighted_edge[j][i] != 0:\n","          summation += weighted_edge[j][i] * score[j]\n","\n","        score[i] = (1 -d) + d * (summation)\n","\n","      if np.sum(np.fabs(prev_score - score)) <= threshold:\n","        break\n","score\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wia32INGlyhA"},"source":["### 5) 핵심 단어 추출"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DMVQR-TqlyhB","colab":{}},"source":["sorted_index = None\n","\n","sorted_index = (np.argsort(score)[::-1])\n","n = 4\n","print(\"\\n=== 핵심키워드 ===\")\n","for i in range(n):\n","    print(str(idx2vocab[sorted_index[i]])+\" : \" + str(score[sorted_index[i]]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AXThGqhpOoaU","colab_type":"code","colab":{}},"source":["sorted_index[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vOuNI7WSBcgU","colab_type":"text"},"source":["---"]},{"cell_type":"code","metadata":{"id":"Nk06RCeMbfyk","colab_type":"code","colab":{}},"source":["import requests \n","from bs4 import BeautifulSoup\n","\n","def get_news_by_url(url):\n","  res = requests.get(url)\n","  bs = BeautifulSoup(res.content, 'html.parser')\n","\n","  title = bs.select('h3#articleTitle')[0].text #제목\n","  content = bs.select('#articleBodyContents')[0].get_text().replace('\\n', \" \") #본문\n","  content = content.replace(\"// flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}\", \"\")\n","  return  content.strip()\n","\n","doc = get_news_by_url('https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=105&oid=018&aid=0004430108')\n","doc[:50]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"683iA8igbfym","colab_type":"text"},"source":["### 1) 토큰화 (Tokenization)\n","\n","분석 텍스트 정제"]},{"cell_type":"code","metadata":{"id":"3SxuV1Zkbfyn","colab_type":"code","colab":{}},"source":["from konlpy.tag import Mecab\n","mecab = Mecab()\n","\n","nodes = [token for token in mecab.pos(doc) if token[1] in ['NNG','NNP']] #NNG, NNP를 스코어 계산 대상(노드)로 제한\n","tokens = [token for token in mecab.pos(doc)] #탐색할 토큰 전체"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m6QRYmRkGJ04","colab_type":"text"},"source":["### 2) 그래프 생성 (weighted edge 계산)"]},{"cell_type":"code","metadata":{"id":"DOCBZA0PGCzl","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8uaL8GwIGXNp","colab_type":"text"},"source":["### 3) 각 노드의 score계산"]},{"cell_type":"code","metadata":{"id":"iZe-PSDoGhOt","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bdg3T37hGbhJ","colab_type":"text"},"source":["### 4)핵심 단어 추출"]},{"cell_type":"code","metadata":{"id":"s3aYD316GauU","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}