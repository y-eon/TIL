{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05 KS Practice_text preprocessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPMB5WqXQi2wMm2ykaQDsRv"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"nhNhOzAgi-hw","colab_type":"text"},"source":["### 1.1 실습용 영문기사 수집\n","- 온라인 기사를 바로 수집하여 실습데이터로 사용  \n","https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/"]},{"cell_type":"code","metadata":{"id":"1Q0fBscdjIby","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594599881422,"user_tz":-540,"elapsed":894,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["import requests\n","from bs4 import BeautifulSoup"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ijMlugRjN-Z","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594599923234,"user_tz":-540,"elapsed":1931,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["url = 'https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissan'\n","response = requests.get(url)\n","soup = BeautifulSoup(response.text,'html.parser')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlaYkEQ5j8Hw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594599962062,"user_tz":-540,"elapsed":1072,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"6f716082-3212-4411-b8ef-1fb91b298574"},"source":["eng_news = soup.select('p') #[class=\"speakable-paragraph\"]')\n","eng_text = eng_news[3].get_text()\n","eng_text"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'Loni Love, Comedian and TV Personality'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"ze-qdyj0kHDw","colab_type":"text"},"source":["### 1.2 영문 토큰화\n","- https://www.nltk.org/api/nltk.tokenize.html"]},{"cell_type":"code","metadata":{"id":"tv_8GpsJk44A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1594600190378,"user_tz":-540,"elapsed":4702,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"b1964c58-1fc5-4281-e74e-202419b7c75a"},"source":["!pip install nltk"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZoOCfqwFk98Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1594600942608,"user_tz":-540,"elapsed":2086,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"d8dd3245-cde7-40fb-acb4-cc2db4db9ee1"},"source":["#word_tokenize() : 단어와 구두점(온점(.), 컴마(,), 물음표(?), 세미콜론(;), 느낌표(!) 등과 같은 기호)으로 구 \n","import nltk \n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize \n","text = 'Good muffins cost $3.88\\nin New York. Please buy me\\ntwo of them.\\n\\nThanks.' \n","word_tokens = word_tokenize(text) \n","print(word_tokens) \n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6-NWDP6mnraR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594601142666,"user_tz":-540,"elapsed":843,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"e3dd8172-bddf-4ae8-dc80-480075fce1bb"},"source":["#word_tokenize() : 단어와 구두점(온점(.), 컴마(,), 물음표(?), 세미콜론(;), 느낌표(!) 등과 같은 기호)으로 구 \n","import nltk \n","from nltk.tokenize import word_tokenize \n","token1 = word_tokenize(eng_text) \n","print(token1) "],"execution_count":12,"outputs":[{"output_type":"stream","text":["['Loni', 'Love', ',', 'Comedian', 'and', 'TV', 'Personality']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"poJask22oYk5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594601161067,"user_tz":-540,"elapsed":793,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"bf4ac5c1-d93e-40d4-b3a0-76c72cc5f69b"},"source":["#WordPunctTokenizer() : 알파벳과 알파벳이 아닌문자를 구분하여 토큰화\n","import nltk\n","from nltk.tokenize import WordPunctTokenizer\n","text = 'Good muffins cost $3.88\\nin New York. Please buy me\\ntwo of them.\\n\\nThanks.'\n","wordpuncttoken = WordPunctTokenizer().tokenize(text)\n","print(wordpuncttoken)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["['Good', 'muffins', 'cost', '$', '3', '.', '88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-aNpJMnnor4Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594601183891,"user_tz":-540,"elapsed":845,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"3c62e1dc-5e27-4327-a631-d64ca79a2ed3"},"source":["#TreebankWordTokenizer() : 정규표현식에 기반한 토큰화\n","import nltk\n","from nltk.tokenize import TreebankWordTokenizer\n","text = 'Good muffins cost $3.88\\nin New York. Please buy me\\ntwo of them.\\n\\nThanks.'\n","treebankwordtoken = TreebankWordTokenizer().tokenize(text)\n","print(treebankwordtoken)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York.', 'Please', 'buy', 'me', 'two', 'of', 'them.', 'Thanks', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aaoD0h9moxcJ","colab_type":"text"},"source":["### 1.3 영문 품사 부착 (PoS Tagging)\n","-분리한 토큰마다 품사를 부착한다  \n","https://www.nltk.org/api/nltk.tag.html  \n","태크목록 : https://pythonprogramming.net/natural-language-toolkit-nltk-part-speech-tagging/"]},{"cell_type":"code","metadata":{"id":"IizDmWBtoziZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1594603705593,"user_tz":-540,"elapsed":1231,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"c393de59-4c45-406c-8c2e-d7be50a4e9df"},"source":["from nltk import pos_tag\n","nltk.download('averaged_perceptron_tagger')\n","taggedToken = pos_tag(word_tokens)\n","print(taggedToken)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[('Good', 'JJ'), ('muffins', 'NNS'), ('cost', 'VBP'), ('$', '$'), ('3.88', 'CD'), ('in', 'IN'), ('New', 'NNP'), ('York', 'NNP'), ('.', '.'), ('Please', 'NNP'), ('buy', 'VB'), ('me', 'PRP'), ('two', 'CD'), ('of', 'IN'), ('them', 'PRP'), ('.', '.'), ('Thanks', 'NNS'), ('.', '.')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a6YQ20yDyY_P","colab_type":"text"},"source":["### 1.4 개체명 인식 (NER, Named Entity Recognition)\n","-http://www.nltk.org/api/nltk.chunk.html"]},{"cell_type":"code","metadata":{"id":"NmHkC4Q0ych7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"status":"ok","timestamp":1594603761775,"user_tz":-540,"elapsed":864,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"3187e8f7-5d49-40c4-9dfd-c5b699f11f60"},"source":["nltk.download('words')\n","nltk.download('maxent_ne_chunker')\n","\n","from nltk import ne_chunk\n","neToken = ne_chunk(taggedToken)\n","print(neToken)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","(S\n","  (GPE Good/JJ)\n","  muffins/NNS\n","  cost/VBP\n","  $/$\n","  3.88/CD\n","  in/IN\n","  (GPE New/NNP York/NNP)\n","  ./.\n","  Please/NNP\n","  buy/VB\n","  me/PRP\n","  two/CD\n","  of/IN\n","  them/PRP\n","  ./.\n","  Thanks/NNS\n","  ./.)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kw06vRcGykaE","colab_type":"text"},"source":["### 1.5 원형 복원\n","- 각 토큰의 원형을 복원하여 표준화 한다."]},{"cell_type":"markdown","metadata":{"id":"lgGsy0c_yq4z","colab_type":"text"},"source":["#### 1.5.1 어간추출 (Stemming)\n","- 규칙에 기반 하여 토큰을 표준화\n","- ning제거, ful 제거 등  \n","https://www.nltk.org/api/nltk.stem.html  \n","규칙상세 : https://tartarus.org/martin/PorterStemmer/def.txt  "]},{"cell_type":"code","metadata":{"id":"5k0ZvV-2y3L8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":123},"executionInfo":{"status":"ok","timestamp":1594603906613,"user_tz":-540,"elapsed":920,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"31a01944-f38a-4138-cc6f-50fc17f05b32"},"source":["from nltk.stem import PorterStemmer\n","ps = PorterStemmer()\n","print(\"running -> \" + ps.stem(\"running\"))\n","# print(\"beautiful -> \" + ps stem(\"beautiful\"))\n","print(\"believes -> \" + ps.stem(\"believes\"))\n","print(\"using -> \" + ps.stem(\"using\"))\n","print(\"conversation -> \" + ps.stem(\"conversation\"))\n","print(\"organization -> \" + ps.stem(\"organization\"))\n","print(\"studies -> \" + ps.stem(\"studies\"))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["running -> run\n","believes -> believ\n","using -> use\n","conversation -> convers\n","organization -> organ\n","studies -> studi\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NJuZ6FJ0y7zc","colab_type":"text"},"source":["#### 1.5.2 표제어 추출 (Lemmatization)\n","품사정보를 보존하여 토큰을 표준화  \n","http://www.nltk.org/api/nltk.stem.html?highlight=lemmatizer"]},{"cell_type":"code","metadata":{"id":"HPo9CBbQzOgM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"status":"ok","timestamp":1594603935046,"user_tz":-540,"elapsed":3632,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"16c2ad52-89b7-4414-c60c-4adcc9389dcf"},"source":["nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","wl = WordNetLemmatizer()\n","print(\"running -> \" + wl.lemmatize(\"running\"))\n","print(\"beautiful -> \" + wl.lemmatize(\"beautiful\"))\n","print(\"believes -> \" + wl.lemmatize(\"believes\"))\n","print(\"using -> \" + wl.lemmatize(\"using\"))\n","print(\"conversation -> \" + wl.lemmatize(\"conversation\"))\n","print(\"organization -> \" + wl.lemmatize(\"organization\"))\n","print(\"studies -> \" + wl.lemmatize(\"studies\"))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","running -> running\n","beautiful -> beautiful\n","believes -> belief\n","using -> using\n","conversation -> conversation\n","organization -> organization\n","studies -> study\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"txSmsimjzQbS","colab_type":"text"},"source":["### 1.6 불용어 처리 (Stopword)"]},{"cell_type":"code","metadata":{"id":"cLkWi6AjzVtr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594603985814,"user_tz":-540,"elapsed":827,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"046b36fb-e01c-45b7-8e2d-2f71c55b6c7e"},"source":["stopPos = ['IN', 'CC', 'UH', 'TO', 'MD', 'DT', 'VBZ','VBP']\n","# 최빈어 조회. 최빈어를 조회하여 불용어 제거 대상을 선정\n","from collections import Counter\n","Counter(taggedToken).most_common()\n","\n","stopWord = [',','be','able']\n","word = []\n","for tag in taggedToken:\n","  if tag[1] not in stopPos:\n","    if tag[0] not in stopWord:\n","      word.append(tag[0])\n","print(word)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["['Good', 'muffins', '$', '3.88', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'them', '.', 'Thanks', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9fpqKexRzah8","colab_type":"text"},"source":["### 1.7 영문 텍스트 전처리 종합"]},{"cell_type":"code","metadata":{"id":"aJsFcQMvzfK0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":461},"executionInfo":{"status":"ok","timestamp":1594604028909,"user_tz":-540,"elapsed":979,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"a416a513-f86b-4021-ad21-6e2a6e56e27a"},"source":["import nltk\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('words')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('wordnet')\n","\n","from nltk.tokenize import TreebankWordTokenizer\n","sumtoken = TreebankWordTokenizer().tokenize(\"Obama loves fried chicken of KFC\")\n","print(sumtoken)\n","from nltk import pos_tag\n","sumTaggedToken = pos_tag(sumtoken)\n","print(sumTaggedToken)\n","from nltk import ne_chunk\n","sumNeToken = ne_chunk(sumTaggedToken)\n","print(sumNeToken)\n","from nltk.stem import PorterStemmer\n","ps = PorterStemmer()\n","print(\"loves -> \" + ps.stem(\"loves\"))\n","print(\"fried -> \" + ps.stem(\"fried\"))\n","from nltk.stem import WordNetLemmatizer\n","wl = WordNetLemmatizer()\n","print(\"loves -> \" + wl.lemmatize(\"loves\"))\n","print(\"fried -> \" + wl.lemmatize(\"fried\"))\n","#불용어 처리\n","sumStopPos = ['IN']\n","sumStopWord = ['fried']\n","word = []\n","for tag in sumTaggedToken:\n","  if tag[1] not in sumStopPos:\n","    if tag[0] not in sumStopWord:\n","      word.append(tag[0])\n","print(word)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","['Obama', 'loves', 'fried', 'chicken', 'of', 'KFC']\n","[('Obama', 'NNP'), ('loves', 'VBZ'), ('fried', 'VBN'), ('chicken', 'NN'), ('of', 'IN'), ('KFC', 'NNP')]\n","(S\n","  (GPE Obama/NNP)\n","  loves/VBZ\n","  fried/VBN\n","  chicken/NN\n","  of/IN\n","  (ORGANIZATION KFC/NNP))\n","loves -> love\n","fried -> fri\n","loves -> love\n","fried -> fried\n","['Obama', 'loves', 'chicken', 'KFC']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"55tDJN-Azn_M","colab_type":"text"},"source":["### 2.2 한글 토큰화 및 형태소 분석\n","- 한글 자연어처리기 비교  \n","https://konlpy.org/ko/latest/morph/"]},{"cell_type":"code","metadata":{"id":"y3AeGY200WBU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":695},"executionInfo":{"status":"ok","timestamp":1594604239183,"user_tz":-540,"elapsed":7574,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"f8b5610d-d084-44ef-e949-b524b638212b"},"source":["# konlpy 설치\n","!pip install konlpy"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 1.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n","Collecting tweepy>=3.7.0\n","  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n","Collecting JPype1>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/9b/e115101a833605b3c0e6f3a2bc1f285c95aaa1d93ab808314ca1bde63eed/JPype1-0.7.5-cp36-cp36m-manylinux2010_x86_64.whl (3.6MB)\n","\u001b[K     |████████████████████████████████| 3.6MB 41.0MB/s \n","\u001b[?25hCollecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 6.9MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Installing collected packages: colorama, tweepy, JPype1, beautifulsoup4, konlpy\n","  Found existing installation: tweepy 3.6.0\n","    Uninstalling tweepy-3.6.0:\n","      Successfully uninstalled tweepy-3.6.0\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-0.7.5 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["bs4"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"DW_TRmo10ZtE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1594604336359,"user_tz":-540,"elapsed":32105,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"7a69b161-c4f6-42cc-e385-18d6b4a8e78f"},"source":["# 코모란(Komoran) 토큰화\n","from konlpy.tag import Komoran\n","komoran= Komoran()\n","kor_text = \"인간이 컴퓨터와 대화하고 있다는 것을 깨닫지 못하고 인간과 대화를 계속할 수 있다면 컴퓨터는 지능적인 것으\"\n","komoran_tokens = komoran.morphs(kor_text)\n","print(komoran_tokens)\n","\n","\n","#한나눔(Hannanum) 토큰화\n","from konlpy.tag import Hannanum\n","hannanum= Hannanum()\n","kor_text = \"인간이 컴퓨터와 대화하고 있다는 것을 깨닫지 못하고 인간과 대화를 계속할 수 있다면 컴퓨터는 지능적인 것으\"\n","hannanum_tokens = hannanum.morphs(kor_text)\n","print(hannanum_tokens)\n","\n","\n","#Okt 토큰화\n","from konlpy.tag import Okt\n","okt= Okt()\n","kor_text = \"인간이 컴퓨터와 대화하고 있다는 것을 깨닫지 못하고 인간과 대화를 계속할 수 있다면 컴퓨터는 지능적인 것으\"\n","okt_tokens = okt.morphs(kor_text)\n","print(okt_tokens)\n","\n","\n","#Kkma 토큰화\n","from konlpy.tag import Kkma\n","kkma= Kkma()\n","kor_text = \"인간이 컴퓨터와 대화하고 있다는 것을 깨닫지 못하고 인간과 대화를 계속할 수 있다면 컴퓨터는 지능적인 것으\"\n","kkma_tokens = kkma.morphs(kor_text)\n","print(kkma_tokens)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["['인간', '이', '컴퓨터', '와', '대화', '하', '고', '있', '다는', '것', '을', '깨닫', '지', '못하', '고', '인간', '과', '대화', '를', '계속', '하', 'ㄹ', '수', '있', '다면', '컴퓨터', '는', '지능', '적', '이', 'ㄴ', '것', '으']\n","['인간', '이', '컴퓨터', '와', '대화', '하고', '있', '다는', '것', '을', '깨닫', '지', '못하', '고', '인간', '과', '대화', '를', '계속', '하', 'ㄹ', '수', '있', '다면', '컴퓨터', '는', '지능적', '이', 'ㄴ', '것으']\n","['인간', '이', '컴퓨터', '와', '대화', '하고', '있다는', '것', '을', '깨닫지', '못', '하고', '인간', '과', '대화', '를', '계속', '할', '수', '있다면', '컴퓨터', '는', '지능', '적', '인', '것', '으']\n","['인간', '이', '컴퓨터', '와', '대화', '하', '고', '있', '다는', '것', '을', '깨닫', '지', '못하', '고', '인간', '과', '대화', '를', '계속', '하', 'ㄹ', '수', '있', '다면', '컴퓨터', '는', '지능', '적', '이', 'ㄴ', '것', '으']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4REp7VOR0j8k","colab_type":"text"},"source":["#### 2.3 한글 품사 부착 (PoS Tagging)\n","- PoS Tag 목록  \n","https://docs.google.com/spreadsheets/u/1/d/1OGAjUvalBuXoZvZ_-  \n","9tEfYD2gQe7hTGsgUpiiBSXI8/edit#gid=0"]},{"cell_type":"code","metadata":{"id":"7mFK6aMN0008","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1594604421693,"user_tz":-540,"elapsed":1201,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"63721798-40d4-4880-eead-af8c4166a777"},"source":["# 코모란(Komoran) 품사 태깅\n","komoranTag = []\n","for token in komoran_tokens:\n","  komoranTag += komoran.pos(token)\n","print(komoranTag)\n","\n","\n","# 한나눔(Hannanum) 품사 태깅\n","hannanumTag = []\n","for token in hannanum_tokens:\n","  hannanumTag += hannanum.pos(token)\n","print(hannanumTag)\n","\n","\n","#Okt 품사 태깅\n","oktTag = []\n","for token in okt_tokens:\n","  oktTag += okt.pos(token)\n","print(oktTag)\n","\n","\n","#Kkma 품사 태깅\n","kkmaTag = []\n","for token in kkma_tokens:\n","  kkmaTag += kkma.pos(token)\n","print(kkmaTag)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["[('인간', 'NNG'), ('이', 'MM'), ('컴퓨터', 'NNG'), ('오', 'VV'), ('아', 'EC'), ('대화', 'NNG'), ('하', 'NNG'), ('고', 'MM'), ('있', 'VV'), ('달', 'VV'), ('는', 'ETM'), ('것', 'NNB'), ('을', 'NNG'), ('깨닫', 'VV'), ('지', 'NNB'), ('못', 'MAG'), ('하', 'MAG'), ('고', 'MM'), ('인간', 'NNG'), ('과', 'NNG'), ('대화', 'NNG'), ('를', 'JKO'), ('계속', 'MAG'), ('하', 'NNG'), ('ㄹ', 'NA'), ('수', 'NNB'), ('있', 'VV'), ('다면', 'NNG'), ('컴퓨터', 'NNG'), ('늘', 'VV'), ('ㄴ', 'ETM'), ('지능', 'NNP'), ('적', 'NNB'), ('이', 'MM'), ('ㄴ', 'JX'), ('것', 'NNB'), ('으', 'NNG')]\n","[('인간', 'N'), ('이', 'M'), ('컴퓨터', 'N'), ('와', 'I'), ('대화', 'N'), ('하', 'P'), ('고', 'E'), ('있', 'N'), ('다', 'M'), ('는', 'J'), ('것', 'N'), ('을', 'N'), ('깨닫', 'N'), ('지', 'N'), ('못하', 'P'), ('어', 'E'), ('고', 'M'), ('인간', 'N'), ('과', 'N'), ('대화', 'N'), ('를', 'N'), ('계속', 'M'), ('하', 'I'), ('ㄹ', 'N'), ('수', 'N'), ('있', 'N'), ('다면', 'N'), ('컴퓨터', 'N'), ('늘', 'P'), ('ㄴ', 'E'), ('지능적', 'N'), ('이', 'M'), ('ㄴ', 'N'), ('것으', 'N')]\n","[('인간', 'Noun'), ('이', 'Noun'), ('컴퓨터', 'Noun'), ('와', 'Verb'), ('대화', 'Noun'), ('하고', 'Verb'), ('있다는', 'Adjective'), ('것', 'Noun'), ('을', 'Josa'), ('깨닫지', 'Verb'), ('못', 'Noun'), ('하고', 'Verb'), ('인간', 'Noun'), ('과', 'Noun'), ('대화', 'Noun'), ('를', 'Noun'), ('계속', 'Noun'), ('할', 'Verb'), ('수', 'Noun'), ('있다면', 'Adjective'), ('컴퓨터', 'Noun'), ('는', 'Verb'), ('지능', 'Noun'), ('적', 'Noun'), ('인', 'Noun'), ('것', 'Noun'), ('으', 'Adverb')]\n","[('인간', 'NNG'), ('이', 'NNG'), ('컴퓨터', 'NNG'), ('오', 'VA'), ('아', 'ECS'), ('대화', 'NNG'), ('하', 'NNG'), ('고', 'NNG'), ('있', 'VA'), ('달', 'VV'), ('는', 'ETD'), ('것', 'NNB'), ('을', 'NNG'), ('깨닫', 'VV'), ('지', 'NNG'), ('못하', 'VX'), ('고', 'NNG'), ('인간', 'NNG'), ('과', 'NNG'), ('대화', 'NNG'), ('를', 'UN'), ('계속', 'MAG'), ('하', 'NNG'), ('ㄹ', 'NNG'), ('수', 'NNG'), ('있', 'VA'), ('다면', 'NNG'), ('컴퓨터', 'NNG'), ('늘', 'VA'), ('ㄴ', 'ETD'), ('지능', 'NNG'), ('적', 'NNG'), ('이', 'NNG'), ('ㄴ', 'NNG'), ('것', 'NNB'), ('으', 'UN')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"89xgAyku09w8","colab_type":"text"},"source":["### 2.4 불용어(Stopword) 처리\n","- 분석에 불필요한 품사를 제거하고, 불필요한 단어(불용어)를 제거한다"]},{"cell_type":"code","metadata":{"id":"wKi48nhY1aq9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"ok","timestamp":1594604514150,"user_tz":-540,"elapsed":793,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"6eb365af-0e90-473b-8469-2fb4cb467751"},"source":["#불용어 처리\n","stopPos = ['Suffix','Punctuation','Josa','Foreign','Alpha','Number']\n","\n","#최빈어 조회. 최빈어를 조회하여 불용어 제거 대상을 선정\n","from collections import Counter\n","Counter(oktTag).most_common()"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(('인간', 'Noun'), 2),\n"," (('컴퓨터', 'Noun'), 2),\n"," (('대화', 'Noun'), 2),\n"," (('하고', 'Verb'), 2),\n"," (('것', 'Noun'), 2),\n"," (('이', 'Noun'), 1),\n"," (('와', 'Verb'), 1),\n"," (('있다는', 'Adjective'), 1),\n"," (('을', 'Josa'), 1),\n"," (('깨닫지', 'Verb'), 1),\n"," (('못', 'Noun'), 1),\n"," (('과', 'Noun'), 1),\n"," (('를', 'Noun'), 1),\n"," (('계속', 'Noun'), 1),\n"," (('할', 'Verb'), 1),\n"," (('수', 'Noun'), 1),\n"," (('있다면', 'Adjective'), 1),\n"," (('는', 'Verb'), 1),\n"," (('지능', 'Noun'), 1),\n"," (('적', 'Noun'), 1),\n"," (('인', 'Noun'), 1),\n"," (('으', 'Adverb'), 1)]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"6StaKy5b1egM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594604544108,"user_tz":-540,"elapsed":874,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"c559b260-c972-4977-d6c7-517d0cd21045"},"source":["stopWord = ['의','이','로','두고','들','를','은','과','수','했다','것','있는','한다','하는','그','있다']\n","word = []\n","for tag in oktTag:\n","  if tag[1] not in stopPos:\n","    if tag[0] not in stopWord:\n","      word.append(tag[0])\n","\n","print(word)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["['인간', '컴퓨터', '와', '대화', '하고', '있다는', '깨닫지', '못', '하고', '인간', '대화', '계속', '할', '있다면', '컴퓨터', '는', '지능', '적', '인', '으']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kr8ML0yE1gRM","colab_type":"text"},"source":["### 2 N-gram"]},{"cell_type":"code","metadata":{"id":"Z07KxptY1rBQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1594604865713,"user_tz":-540,"elapsed":6602,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"9f7a738c-114b-4b81-97c5-25b7945c9080"},"source":["import nltk\n","from nltk import bigrams, word_tokenize\n","from nltk.util import ngrams\n","nltk.download('punkt')\n","\n","sentence = \"I am a boy.\"\n","tokens = word_tokenize(sentence)\n","\n","bigram = bigrams(tokens)\n","trigram = ngrams(tokens, 3)\n","\n","for t in bigram:\n","  print(t)\n","\n","for t in trigram:\n","  print(t)\n","\n","import nltk\n","nltk.download('movie_reviews')\n","nltk.download('punkt')\n","\n","from nltk.corpus import movie_reviews\n","sentences = []\n","for tokens in movie_reviews.sents():\n","  bigram = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol=\"SS\") #right_p\n","  sentences += [t for t in bigram]\n","\n","sentences[:20]\n","\n","movie_reviews.sents()\n","\n","sentences[-5:]"],"execution_count":42,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","('I', 'am')\n","('am', 'a')\n","('a', 'boy')\n","('boy', '.')\n","('I', 'am', 'a')\n","('am', 'a', 'boy')\n","('a', 'boy', '.')\n","[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/movie_reviews.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[('whatever', 'it'), ('it', 'may'), ('may', 'be'), ('be', '.'), ('.', None)]"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"BtjAYh4s1060","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}