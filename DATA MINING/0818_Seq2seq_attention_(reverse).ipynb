{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"nmt_with_attention_start(reverse)_완료.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"s_qNSzzyaCbD"},"source":["##### Copyright 2019 The TensorFlow Authors."]},{"cell_type":"code","metadata":{"cellView":"form","colab_type":"code","id":"jmjh290raIky","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"J0Qjg6vuaHNt"},"source":["# Neural machine translation with attention"]},{"cell_type":"code","metadata":{"id":"Zri7xVrRBZ_g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1597727048921,"user_tz":-540,"elapsed":20649,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"c28f9783-f4c9-4cc8-ba72-46f98a887f31"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tnxXKDjq3jEL","colab":{},"executionInfo":{"status":"ok","timestamp":1597727055066,"user_tz":-540,"elapsed":3285,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","from sklearn.model_selection import train_test_split\n","import unicodedata\n","import re\n","import numpy as np\n","import os\n","import io\n","import time\n","import pandas as pd\n","import re"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"MmuTHd2vBjSZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597727202779,"user_tz":-540,"elapsed":5117,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["df= pd.read_excel('/content/gdrive/My Drive/Seq2Seq/data/kor.xlsx',sheet_name=1)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVeZI-EZBoTm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597727202783,"user_tz":-540,"elapsed":5104,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["# Download the file\n","path_to_file = '/content/gdrive/My Drive/Seq2Seq/data/kor.xlsx'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rd0jw-eC3jEh","colab":{},"executionInfo":{"status":"ok","timestamp":1597727202785,"user_tz":-540,"elapsed":5101,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["# # Converts the unicode file to ascii\n","# def unicode_to_ascii(s):\n","#   return ''.join(c for c in unicodedata.normalize('NFD', s)\n","#       if unicodedata.category(c) != 'Mn')\n","\n","\n","# def preprocess_sentence(w):\n","#   w = w.lower().strip()\n","\n","#   # creating a space between a word and the punctuation following it\n","#   # eg: \"he is a boy.\" => \"he is a boy .\"\n","#   # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n","#   w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n","#   w = re.sub(r'[\" \"]+', \" \", w)\n","  \n","#   # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","#   w = re.sub(r\"[^ㄱ-ㅣ가-힣a-zA-Z?.!,]+\", \" \", w)\n","#   # w = re.sub(r\"[^ ㄱ-ㅣ가-힣?.!,¿]+\", \" \", w)\n","#   w = w.strip()\n","\n","#   # adding a start and an end token to the sentence\n","#   # so that the model know when to start and stop predicting.\n","#   if len(re.findall('[ㄱ-ㅣ가-힣]+',w)) == 0:\n","#     w = '<start> ' + w + ' <end>'\n","#   return w"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"CZE7d4gMCqJj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597727202785,"user_tz":-540,"elapsed":5094,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["#################################reverse_진행###############################################\n","def preprocess_sentence(w):\n","  w = w.lower().strip()\n","  # creating a space between a word and the punctuation following it\n","  # eg: \"he is a boy.\" => \"he is a boy .\"\n","  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n","  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n","  w = re.sub(r'[\" \"]+', \" \", w)\n","  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","  w = re.sub(r\"[^ㄱ-ㅣ가-힣a-zA-Z?.!,]+\", \" \", w)\n","  # w = re.sub(r\"[^ ㄱ-ㅣ가-힣?.!,¿]+\", \" \", w)\n","  w = w.strip()\n","  # adding a start and an end token to the sentence\n","  # so that the model know when to start and stop predicting.\n","  if len(re.findall('[ㄱ-ㅣ가-힣]+',w)) == 0:\n","    w = '<start> ' + w + ' <end>'\n","  else :\n","    # reverse\n","    w = '<start> ' + w[::-1] + ' <end>'\n","    # w = w[::-1]\n","  return w"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"opI2GzOt479E","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1597727202786,"user_tz":-540,"elapsed":5079,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"5c064541-c6fe-4dee-efa9-373315588c3b"},"source":["ko_sentence = '나는 매일 저녁 배트를 만나러 다락방으로 가요.'\n","en_sentence = \"I go to the attic every evening to meet Bat.\"\n","print(preprocess_sentence(en_sentence))\n","print(preprocess_sentence(ko_sentence))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["<start> i go to the attic every evening to meet bat . <end>\n","<start> . 요가 로으방락다 러나만 를트배 녁저 일매 는나 <end>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OHn4Dct23jEm","colab":{},"executionInfo":{"status":"ok","timestamp":1597727202786,"user_tz":-540,"elapsed":5074,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["def create_dataset(path, num_examples):\n","  df = pd.read_excel(path,sheet_name=1)\n","  col = df.columns\n","  lines = df[col[1]] +'\\t'+ df[col[2]]\n","  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n","\n","  return zip(*word_pairs)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cTbSbBz55QtF","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1597727208298,"user_tz":-540,"elapsed":10567,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"428c923a-5e4d-4ceb-fc0a-3ce91fea96cd"},"source":["en, sp = create_dataset(path_to_file, None)\n","print(en[-1])\n","print(sp[-1])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["<start> . 죠들힘 이많 엔기기즐 를츠포스 이들이아 린어 <end>\n","<start> it is difficult for young children to enjoy sports . <end>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bIOn8RCNDJXG","colab":{},"executionInfo":{"status":"ok","timestamp":1597727208299,"user_tz":-540,"elapsed":10562,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["def tokenize(lang):\n","  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='',oov_token='<UNK>')\n","  lang_tokenizer.fit_on_texts(lang)\n","\n","  tensor = lang_tokenizer.texts_to_sequences(lang)\n","\n","  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n","                                                         padding='post')\n","\n","  return tensor, lang_tokenizer"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eAY9k49G3jE_","colab":{},"executionInfo":{"status":"ok","timestamp":1597727208300,"user_tz":-540,"elapsed":10558,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["def load_dataset(path, num_examples=None):\n","  # creating cleaned input, output pairs\n","  inp_lang, targ_lang = create_dataset(path, num_examples)\n","\n","  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n","  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n","\n","  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GOi42V79Ydlr"},"source":["### Limit the size of the dataset to experiment faster (optional)\n","\n","Training on the complete dataset of >100,000 sentences will take a long time. To train faster, we can limit the size of the dataset to 30,000 sentences (of course, translation quality degrades with less data):"]},{"cell_type":"code","metadata":{"id":"nRo9O9EE7e0d","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597727208301,"user_tz":-540,"elapsed":10553,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["# import pandas as pd\n","# news_df = pd.read_excel('/content/drive/My Drive/B반/data/kor.xlsx', sheet_name='Sheet1')\n","# train_df, val_df, test_df = news_df.iloc[:50000, 1:], news_df.iloc[50000:63000, 1:], news_df.iloc[63000:, 1:]"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cnxC7q-j3jFD","colab":{},"executionInfo":{"status":"ok","timestamp":1597727216696,"user_tz":-540,"elapsed":18943,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["# Try experimenting with the size of that dataset\n","num_examples = 75000\n","input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n","input_tensor, target_tensor = input_tensor[:63000, 1:], target_tensor[:63000, 1:]\n","xtest_tensor = input_tensor[63000:,1:]\n","ytest_tensor =target_tensor[63000:,1:]\n","# Calculate max_length of the target tensors\n","max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"2CxfW9zGG-iG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597727216699,"user_tz":-540,"elapsed":18928,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"c74ab3af-7a1c-4c72-eae0-3d18b4658d19"},"source":["input_tensor.shape, target_tensor.shape"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((63000, 20), (63000, 20))"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4QILQkOs3jFG","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597727216700,"user_tz":-540,"elapsed":18912,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"d3891973-ea42-43a7-c2de-5e8444f7fbc3"},"source":["# Creating training and validation sets using an 80-20 split\n","input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=13000,random_state=42)\n","\n","# Show length\n","print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["50000 50000 13000 13000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lJPmLZGMeD5q","colab":{},"executionInfo":{"status":"ok","timestamp":1597727216701,"user_tz":-540,"elapsed":18910,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["def convert(lang, tensor):\n","  for t in tensor:\n","    if t!=0:\n","      print (\"%d ----> %s\" % (t, lang.index_word[t]))"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VXukARTDd7MT","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1597727216701,"user_tz":-540,"elapsed":18893,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"59f2be9c-dfe9-4f1e-bfdf-3fe97cecf4a2"},"source":["print (\"Input Language; index to word mapping\")\n","convert(inp_lang, input_tensor_train[0])\n","print ()\n","print (\"Target Language; index to word mapping\")\n","convert(targ_lang, target_tensor_train[0])"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Input Language; index to word mapping\n","4 ----> .\n","1778 ----> 요나만\n","8319 ----> 서에꿈\n","956 ----> 고자\n","48779 ----> 고덮꼭\n","24505 ----> 불이\n","3 ----> <end>\n","\n","Target Language; index to word mapping\n","13451 ----> tucked\n","13 ----> in\n","87 ----> well\n","16 ----> and\n","362 ----> sleep\n","11 ----> ,\n","111 ----> see\n","8 ----> you\n","13 ----> in\n","29 ----> your\n","1336 ----> dreams\n","4 ----> .\n","3 ----> <end>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rgCLkfv5uO3d"},"source":["### Create a tf.data dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TqHsArVZ3jFS","colab":{},"executionInfo":{"status":"ok","timestamp":1597727222282,"user_tz":-540,"elapsed":24468,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 64\n","steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n","embedding_dim = 256\n","units = 1024\n","vocab_inp_size = len(inp_lang.word_index)+1\n","vocab_tar_size = len(targ_lang.word_index)+1\n","\n","dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qc6-NK1GtWQt","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597727222283,"user_tz":-540,"elapsed":24451,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"16efa5fd-5b09-4ee6-a56d-76c8e645414b"},"source":["example_input_batch, example_target_batch = next(iter(dataset))\n","example_input_batch.shape, example_target_batch.shape"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 20]), TensorShape([64, 20]))"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nZ2rI24i3jFg","colab":{},"executionInfo":{"status":"ok","timestamp":1597727222284,"user_tz":-540,"elapsed":24447,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["class Encoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","    super(Encoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.enc_units = enc_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.enc_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","\n","  def call(self, x, hidden):\n","    x = self.embedding(x)\n","    output, state = self.gru(x, initial_state = hidden)\n","    return output, state\n","\n","  def initialize_hidden_state(self):\n","    return tf.zeros((self.batch_sz, self.enc_units))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"60gSVh05Jl6l","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1597727227337,"user_tz":-540,"elapsed":29485,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"eb916b17-0226-4ba0-af74-8a2106fd798e"},"source":["encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","\n","# sample input\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n","print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Encoder output shape: (batch size, sequence length, units) (64, 20, 1024)\n","Encoder Hidden state shape: (batch size, units) (64, 1024)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"umohpBN2OM94","colab":{},"executionInfo":{"status":"ok","timestamp":1597727227339,"user_tz":-540,"elapsed":29482,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["class BahdanauAttention(tf.keras.layers.Layer):\n","  def __init__(self, units):\n","    super(BahdanauAttention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.V = tf.keras.layers.Dense(1)\n","\n","  def call(self, query, values):\n","    # query hidden state shape == (batch_size, hidden size)\n","    # query_with_time_axis shape == (batch_size, 1, hidden size)\n","    # values shape == (batch_size, max_len, hidden size)\n","    # we are doing this to broadcast addition along the time axis to calculate the score\n","    query_with_time_axis = tf.expand_dims(query, 1)\n","\n","    # score shape == (batch_size, max_length, 1)\n","    # we get 1 at the last axis because we are applying score to self.V\n","    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n","    score = self.V(tf.nn.tanh(\n","        self.W1(query_with_time_axis) + self.W2(values)))\n","\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    attention_weights = tf.nn.softmax(score, axis=1)\n","\n","    # context_vector shape after sum == (batch_size, hidden_size)\n","    context_vector = attention_weights * values\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","    return context_vector, attention_weights"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"k534zTHiDjQU","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1597727229797,"user_tz":-540,"elapsed":31927,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"4cddd59c-f0a0-4d78-df64-3bc5fd3977c1"},"source":["attention_layer = BahdanauAttention(10)\n","attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n","\n","print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n","print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Attention result shape: (batch size, units) (64, 1024)\n","Attention weights shape: (batch_size, sequence_length, 1) (64, 20, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yJ_B3mhW3jFk","colab":{},"executionInfo":{"status":"ok","timestamp":1597727229799,"user_tz":-540,"elapsed":31925,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","    super(Decoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.dec_units = dec_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.dec_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","    # used for attention\n","    self.attention = BahdanauAttention(self.dec_units)\n","\n","  def call(self, x, hidden, enc_output):\n","    # enc_output shape == (batch_size, max_length, hidden_size)\n","    context_vector, attention_weights = self.attention(hidden, enc_output)\n","\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","    x = self.embedding(x)\n","\n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","    # passing the concatenated vector to the GRU\n","    output, state = self.gru(x)\n","\n","    # output shape == (batch_size * 1, hidden_size)\n","    output = tf.reshape(output, (-1, output.shape[2]))\n","\n","    # output shape == (batch_size, vocab)\n","    x = self.fc(output)\n","\n","    return x, state, attention_weights"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P5UY8wko3jFp","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597727229800,"user_tz":-540,"elapsed":31898,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"97593e8e-e793-4d01-a3b9-a9550ac3a50e"},"source":["decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n","\n","sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n","                                      sample_hidden, sample_output)\n","\n","print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Decoder output shape: (batch_size, vocab size) (64, 19232)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_ch_71VbIRfK"},"source":["## Define the optimizer and the loss function"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WmTHr5iV3jFr","colab":{},"executionInfo":{"status":"ok","timestamp":1597727229801,"user_tz":-540,"elapsed":31896,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["optimizer = tf.keras.optimizers.Adam()\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DMVWzzsfNl4e"},"source":["## Checkpoints (Object-based saving)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Zj8bXQTgNwrF","colab":{},"executionInfo":{"status":"ok","timestamp":1597727229802,"user_tz":-540,"elapsed":31892,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["checkpoint_dir = './training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hpObfY22IddU"},"source":["## Training\n","\n","1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n","2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n","3. The decoder returns the *predictions* and the *decoder hidden state*.\n","4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n","5. Use *teacher forcing* to decide the next input to the decoder.\n","6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n","7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sC9ArXSsVfqn","colab":{},"executionInfo":{"status":"ok","timestamp":1597727229802,"user_tz":-540,"elapsed":31889,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","  loss = 0\n","\n","  with tf.GradientTape() as tape:\n","    enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n","\n","    # Teacher forcing - feeding the target as the next input\n","    for t in range(1, targ.shape[1]):\n","      # passing enc_output to the decoder\n","      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","\n","      loss += loss_function(targ[:, t], predictions)\n","\n","      # using teacher forcing\n","      dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","  batch_loss = (loss / int(targ.shape[1]))\n","\n","  variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","  gradients = tape.gradient(loss, variables)\n","\n","  optimizer.apply_gradients(zip(gradients, variables))\n","\n","  return batch_loss"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ddefjBMa3jF0","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d094661b-e46c-429a-9e35-94a54b32f02f"},"source":["EPOCHS = 10\n","\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_loss = 0\n","\n","  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","    batch_loss = train_step(inp, targ, enc_hidden)\n","    total_loss += batch_loss\n","\n","    if batch % 100 == 0:\n","      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                   batch,\n","                                                   batch_loss.numpy()))\n","  # saving (checkpoint) the model every 2 epochs\n","  if (epoch + 1) % 2 == 0:\n","    checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 5.2327\n","Epoch 1 Batch 100 Loss 2.8308\n","Epoch 1 Batch 200 Loss 2.8667\n","Epoch 1 Batch 300 Loss 2.7150\n","Epoch 1 Batch 400 Loss 2.4783\n","Epoch 1 Batch 500 Loss 2.5232\n","Epoch 1 Batch 600 Loss 2.4629\n","Epoch 1 Batch 700 Loss 2.5724\n","Epoch 1 Loss 2.7519\n","Time taken for 1 epoch 332.2483584880829 sec\n","\n","Epoch 2 Batch 0 Loss 2.4036\n","Epoch 2 Batch 100 Loss 2.3771\n","Epoch 2 Batch 200 Loss 2.4440\n","Epoch 2 Batch 300 Loss 2.3441\n","Epoch 2 Batch 400 Loss 2.3882\n","Epoch 2 Batch 500 Loss 2.3426\n","Epoch 2 Batch 600 Loss 2.3512\n","Epoch 2 Batch 700 Loss 2.3615\n","Epoch 2 Loss 2.3472\n","Time taken for 1 epoch 315.9720757007599 sec\n","\n","Epoch 3 Batch 0 Loss 2.2522\n","Epoch 3 Batch 100 Loss 2.1353\n","Epoch 3 Batch 200 Loss 2.1467\n","Epoch 3 Batch 300 Loss 2.1606\n","Epoch 3 Batch 400 Loss 2.2963\n","Epoch 3 Batch 500 Loss 2.1919\n","Epoch 3 Batch 600 Loss 2.1006\n","Epoch 3 Batch 700 Loss 2.2101\n","Epoch 3 Loss 2.1934\n","Time taken for 1 epoch 313.8329727649689 sec\n","\n","Epoch 4 Batch 0 Loss 2.0008\n","Epoch 4 Batch 100 Loss 2.1324\n","Epoch 4 Batch 200 Loss 2.0806\n","Epoch 4 Batch 300 Loss 1.9296\n","Epoch 4 Batch 400 Loss 2.0085\n","Epoch 4 Batch 500 Loss 2.1356\n","Epoch 4 Batch 600 Loss 2.0318\n","Epoch 4 Batch 700 Loss 2.0822\n","Epoch 4 Loss 2.0684\n","Time taken for 1 epoch 315.50729513168335 sec\n","\n","Epoch 5 Batch 0 Loss 2.0114\n","Epoch 5 Batch 100 Loss 1.9635\n","Epoch 5 Batch 200 Loss 2.0363\n","Epoch 5 Batch 300 Loss 2.1085\n","Epoch 5 Batch 400 Loss 1.9366\n","Epoch 5 Batch 500 Loss 1.9267\n","Epoch 5 Batch 600 Loss 1.9776\n","Epoch 5 Batch 700 Loss 2.0411\n","Epoch 5 Loss 1.9492\n","Time taken for 1 epoch 314.5453369617462 sec\n","\n","Epoch 6 Batch 0 Loss 1.8224\n","Epoch 6 Batch 100 Loss 1.7156\n","Epoch 6 Batch 200 Loss 1.7660\n","Epoch 6 Batch 300 Loss 1.9861\n","Epoch 6 Batch 400 Loss 1.9611\n","Epoch 6 Batch 500 Loss 1.7869\n","Epoch 6 Batch 600 Loss 1.9144\n","Epoch 6 Batch 700 Loss 1.8444\n","Epoch 6 Loss 1.8335\n","Time taken for 1 epoch 317.31366419792175 sec\n","\n","Epoch 7 Batch 0 Loss 1.6364\n","Epoch 7 Batch 100 Loss 1.6430\n","Epoch 7 Batch 200 Loss 1.7420\n","Epoch 7 Batch 300 Loss 1.7039\n","Epoch 7 Batch 400 Loss 1.7080\n","Epoch 7 Batch 500 Loss 1.7641\n","Epoch 7 Batch 600 Loss 1.7066\n","Epoch 7 Batch 700 Loss 1.7054\n","Epoch 7 Loss 1.7068\n","Time taken for 1 epoch 313.78099274635315 sec\n","\n","Epoch 8 Batch 0 Loss 1.4997\n","Epoch 8 Batch 100 Loss 1.5261\n","Epoch 8 Batch 200 Loss 1.5918\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mU3Ce8M6I3rz"},"source":["## Translate\n","\n","* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n","* Stop predicting when the model predicts the *end token*.\n","* And store the *attention weights for every time step*.\n","\n","Note: The encoder output is calculated only once for one input."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EbQpyYs13jF_","colab":{}},"source":["def evaluate(sentence):\n","  attention_plot = np.zeros((max_length_targ, max_length_inp))\n","\n","  sentence = preprocess_sentence(sentence)\n","\n","  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n","  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n","                                                         maxlen=max_length_inp,\n","                                                         padding='post')\n","  inputs = tf.convert_to_tensor(inputs)\n","\n","  result = ''\n","\n","  hidden = [tf.zeros((1, units))]\n","  enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","  dec_hidden = enc_hidden\n","  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n","\n","  for t in range(max_length_targ):\n","    predictions, dec_hidden, attention_weights = decoder(dec_input,\n","                                                         dec_hidden,\n","                                                         enc_out)\n","\n","    # storing the attention weights to plot later on\n","    attention_weights = tf.reshape(attention_weights, (-1, ))\n","    attention_plot[t] = attention_weights.numpy()\n","\n","    predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","    result += targ_lang.index_word[predicted_id] + ' '\n","\n","    if targ_lang.index_word[predicted_id] == '<end>':\n","      return result, sentence, attention_plot\n","\n","    # the predicted ID is fed back into the model\n","    dec_input = tf.expand_dims([predicted_id], 0)\n","\n","  return result, sentence, attention_plot"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"s5hQWlbN3jGF","colab":{}},"source":["# function for plotting the attention weights\n","def plot_attention(attention, sentence, predicted_sentence):\n","  fig = plt.figure(figsize=(10,10))\n","  ax = fig.add_subplot(1, 1, 1)\n","  ax.matshow(attention, cmap='viridis')\n","\n","  fontdict = {'fontsize': 14}\n","\n","  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n","  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n","\n","  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sl9zUHzg3jGI","colab":{}},"source":["def translate(sentence):\n","  result, sentence, attention_plot = evaluate(sentence)\n","\n","  # print('Input: %s' % (sentence))\n","  # print('Predicted translation: {}'.format(result))\n","  return result.replace(' <end>','')\n","\n","  # attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","  # plot_attention(attention_plot, sentence.split(' '), result.split(' '))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"n250XbnjOaqP"},"source":["## Restore the latest checkpoint and test"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UJpT9D5_OgP6","colab":{}},"source":["# restoring the latest checkpoint in checkpoint_dir\n","checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eW7nsqDZM42z","colab_type":"code","colab":{}},"source":["df['en'].iloc[3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYeTlyRA3CmI","colab_type":"code","colab":{}},"source":["df['en'].iloc[11]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Th2tNLC3G7H","colab_type":"code","colab":{}},"source":["df['ko'].iloc[3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mpPhOtrY3MGk","colab_type":"code","colab":{}},"source":["df['ko'].iloc[11]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WrAM0FDomq3E","colab":{}},"source":["translate('어린 아이들이 스포츠를 즐기기엔 많이 힘들죠.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zSx2iM36EZQZ","colab":{}},"source":["translate('나는 오늘 자정에 한국으로 돌아 가요.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"A3LLCx3ZE0Ls","colab":{}},"source":["translate('그는 조금 있으면 수원으로 가요.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UeavW0y6NHbk","colab_type":"code","colab":{}},"source":["translate('선생님이 밥을 먹으러 갔다.')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"32Z7JdhNfEda","colab_type":"text"},"source":["## BLEU SCORE"]},{"cell_type":"code","metadata":{"id":"MHGjijEIbJbN","colab_type":"code","colab":{}},"source":["from tqdm.notebook import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HMqmjSIpqAW9","colab_type":"code","colab":{}},"source":["# ref = []\n","# pred = []\n","# for i in tqdm(range(63000,67501)):\n","#   ref.append(df['en'].iloc[i])\n","#   pred.append(translate(df['ko'].iloc[i]))\n","# for i in tqdm(range(67501,75001)):\n","#   ref.append(df['en'].iloc[i])\n","#   pred.append(translate(df['ko'].iloc[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"El7wQ9Xs54fv","colab_type":"code","colab":{}},"source":["import nltk.translate.bleu_score as bleu\n","from nltk.translate.bleu_score import SmoothingFunction\n","def sentences_to_bleu(ref, pred):\n","  \"\"\"\n","  ref : 참고용 타겟 문장(학습용 영어 문장)\n","  pred : 예측 문장(번역 결과)\n","  \"\"\"\n","  smoothie = SmoothingFunction().method4\n","  return bleu.sentence_bleu(ref,pred, smoothing_function=smoothie)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"An14xFjffssO","colab_type":"code","colab":{}},"source":["score = []\n","for i in tqdm(range(63000,75000)):\n","  score.append(sentences_to_bleu([[df['en'].iloc[i]]],translate(df['ko'].iloc[i])))\n","BLUE = np.mean(score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fz4rslrQVVum","colab_type":"code","colab":{}},"source":["BLUE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ong-sfuHgSgL","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}